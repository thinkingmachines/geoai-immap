{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "This notebook implements prediction using sliding window approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "import model_utils\n",
    "import geoutils\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '20200509'\n",
    "data_dir = \"../data/\"\n",
    "model_dir = '../models/'\n",
    "output_dir = \"../outputs/probmaps/\"\n",
    "input_file = data_dir + '{}_dataset.csv'.format(version)\n",
    "\n",
    "images_dir = data_dir + 'images/'\n",
    "indices_dir = data_dir + 'indices/'\n",
    "pos_mask_dir = data_dir + 'pos_masks/'\n",
    "neg_mask_dir = data_dir + 'neg_masks/'\n",
    "tmp_dir = data_dir + 'tmp/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -q -m cp gs://immap-images/20200531/*.tif {images_dir}\n",
    "!gsutil -q -m cp gs://immap-indices/20200531/*.tif {indices_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimensions: (1029869, 69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1_2015-2016</th>\n",
       "      <th>B2_2015-2016</th>\n",
       "      <th>B3_2015-2016</th>\n",
       "      <th>B4_2015-2016</th>\n",
       "      <th>B5_2015-2016</th>\n",
       "      <th>B6_2015-2016</th>\n",
       "      <th>B7_2015-2016</th>\n",
       "      <th>B8_2015-2016</th>\n",
       "      <th>B9_2015-2016</th>\n",
       "      <th>B10_2015-2016</th>\n",
       "      <th>...</th>\n",
       "      <th>mndwi_2019-2020</th>\n",
       "      <th>ui_2019-2020</th>\n",
       "      <th>nbi_2019-2020</th>\n",
       "      <th>brba_2019-2020</th>\n",
       "      <th>nbai_2019-2020</th>\n",
       "      <th>mbi_2019-2020</th>\n",
       "      <th>baei_2019-2020</th>\n",
       "      <th>target</th>\n",
       "      <th>uid</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.13225</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>0.16430</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.25700</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.25510</td>\n",
       "      <td>0.32295</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438625</td>\n",
       "      <td>0.151655</td>\n",
       "      <td>0.209614</td>\n",
       "      <td>0.479385</td>\n",
       "      <td>-0.665204</td>\n",
       "      <td>-0.060444</td>\n",
       "      <td>0.948025</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.15100</td>\n",
       "      <td>0.12885</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.16185</td>\n",
       "      <td>0.1899</td>\n",
       "      <td>0.25700</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.25755</td>\n",
       "      <td>0.32295</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435450</td>\n",
       "      <td>0.151655</td>\n",
       "      <td>0.213526</td>\n",
       "      <td>0.488330</td>\n",
       "      <td>-0.663010</td>\n",
       "      <td>-0.059064</td>\n",
       "      <td>0.952352</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15895</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.15185</td>\n",
       "      <td>0.18915</td>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.28555</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.28085</td>\n",
       "      <td>0.35740</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447333</td>\n",
       "      <td>0.145385</td>\n",
       "      <td>0.222971</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>-0.661291</td>\n",
       "      <td>-0.060496</td>\n",
       "      <td>0.911748</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B1_2015-2016  B2_2015-2016  B3_2015-2016  B4_2015-2016  B5_2015-2016  \\\n",
       "0       0.15100       0.13225       0.14240       0.16430        0.1899   \n",
       "1       0.15100       0.12885       0.13790       0.16185        0.1899   \n",
       "2       0.15895       0.13730       0.15185       0.18915        0.2264   \n",
       "\n",
       "   B6_2015-2016  B7_2015-2016  B8_2015-2016  B9_2015-2016  B10_2015-2016  ...  \\\n",
       "0       0.25700        0.2960       0.25510       0.32295         0.0396  ...   \n",
       "1       0.25700        0.2960       0.25755       0.32295         0.0396  ...   \n",
       "2       0.28555        0.3268       0.28085       0.35740         0.0416  ...   \n",
       "\n",
       "   mndwi_2019-2020  ui_2019-2020  nbi_2019-2020  brba_2019-2020  \\\n",
       "0        -0.438625      0.151655       0.209614        0.479385   \n",
       "1        -0.435450      0.151655       0.213526        0.488330   \n",
       "2        -0.447333      0.145385       0.222971        0.473118   \n",
       "\n",
       "   nbai_2019-2020  mbi_2019-2020  baei_2019-2020  target  uid  area  \n",
       "0       -0.665204      -0.060444        0.948025       3   39     0  \n",
       "1       -0.663010      -0.059064        0.952352       3   39     0  \n",
       "2       -0.661291      -0.060496        0.911748       3   39     0  \n",
       "\n",
       "[3 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(input_file).reset_index(drop=True)\n",
    "features = [column  for column in data.columns[:-3]]\n",
    "print('Data dimensions: {}'.format(data.shape))\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, solver='warn') #scikit-learn==0.21.3\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=800, \n",
    "    max_depth=12, \n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'model_LR_30k': lr, # trains for 30mins\n",
    "    'model_RF_30k': rf, # trains for <2mins\n",
    "}\n",
    "for f, clf in clfs.items():\n",
    "    print(f)\n",
    "    model, features = model_utils.train_model(clf, data, num_neg_samples=30000, random_state=SEED)\n",
    "    filename = model_dir + f'{f}.sav'\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['LR_30k', 'RF_30k']\n",
    "models = []\n",
    "for model_name in model_names:\n",
    "    filename = '{}model_{}.sav'.format(model_dir, model_name)\n",
    "    models.append(joblib.load(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing soacha...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [01:18<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "areas = list(set([image.split('_')[0] for image in os.listdir(images_dir)]))\n",
    "area_dict = geoutils.get_filepaths(areas, images_dir, indices_dir)\n",
    "\n",
    "for area in areas:\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        out_dir = output_dir + model_name + '/'\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        output = '{}{}_{}_{}.tif'.format(\n",
    "            out_dir, version, area, model_name\n",
    "        )\n",
    "        if not os.path.isfile(output):\n",
    "            geoutils.get_preds_windowing(\n",
    "                area=area, \n",
    "                area_dict=area_dict,\n",
    "                model=model, \n",
    "                tmp_dir=tmp_dir,\n",
    "                best_features=features,  \n",
    "                output=output, \n",
    "                grid_blocks=9,\n",
    "                threshold=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 82.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:18<00:00,  4.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:03<00:00, 26.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 44.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 53.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 86.13it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 44.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 52.84it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:05<00:00, 14.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 86.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:12<00:00,  6.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.94it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:11<00:00,  7.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:02<00:00, 31.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:04<00:00, 18.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:04<00:00, 17.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:04<00:00, 18.16it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:02<00:00, 30.81it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 43.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 53.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:15<00:00,  5.23it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 41.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 42.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 74.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:04<00:00, 19.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 63.95it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:10<00:00,  7.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 93.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 42.92it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 115.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:06<00:00, 12.85it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:08<00:00,  9.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 114.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 66.35it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:29<00:00,  2.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:04<00:00, 20.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:16<00:00,  4.99it/s]\n"
     ]
    }
   ],
   "source": [
    "areas = list(set([image.split('_')[0] for image in os.listdir(images_dir)]))\n",
    "for area in areas:\n",
    "    filename1 = '{0:}{3:}/{1:}_{2:}_{3:}.tif'.format(\n",
    "        output_dir, version, area, model_names[0]\n",
    "    )\n",
    "    filename2 = '{0:}{3:}/{1:}_{2:}_{3:}.tif'.format(\n",
    "        output_dir, version, area, model_names[1]\n",
    "    )\n",
    "    out_dir = output_dir + 'ensembled/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    output_file = '{}{}_{}.tif'.format(out_dir, version, area)\n",
    "    geoutils.get_rasters_merged(\n",
    "        filename1,\n",
    "        filename2,\n",
    "        output_file,\n",
    "        tmp_dir,\n",
    "        grid_blocks=9\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in os.listdir(model_dir):\n",
    "    filename = model_dir + model\n",
    "    !gsutil -q cp {filename} gs://immap-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['ensembled']: \n",
    "    out_dir = output_dir + model_name + '/'\n",
    "    for filename in os.listdir(out_dir):\n",
    "        bucket = 'gs://immap-output/{}/{}/'.format(version, model_name)\n",
    "        !gsutil -q cp {out_dir + filename} {bucket}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
